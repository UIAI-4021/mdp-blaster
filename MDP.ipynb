{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43732b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T07:06:01.812998800Z",
     "start_time": "2023-12-06T07:06:01.652032200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import nessary libraries\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.cliffwalking import CliffWalkingEnv\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "from os import path\n",
    "from numpy import argmax\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a570958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T07:06:02.143241100Z",
     "start_time": "2023-12-06T07:06:02.114457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do not change this class\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "image_path = path.join(path.dirname(gym.__file__), \"envs\", \"toy_text\")\n",
    "\n",
    "class CliffWalking(CliffWalkingEnv):\n",
    "    def __init__(self, is_hardmode=True, num_cliffs=10, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.is_hardmode = is_hardmode\n",
    "\n",
    "        # Generate random cliff positions\n",
    "        if self.is_hardmode:\n",
    "            self.num_cliffs = num_cliffs\n",
    "            self._cliff = np.zeros(self.shape, dtype=bool)\n",
    "            self.start_state = (3, 0)\n",
    "            self.terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "            self.cliff_positions = []\n",
    "            while len(self.cliff_positions) < self.num_cliffs:\n",
    "                new_row = np.random.randint(0, 4)\n",
    "                new_col = np.random.randint(0, 11)\n",
    "                state = (new_row, new_col)\n",
    "                if (\n",
    "                    (state not in self.cliff_positions)\n",
    "                    and (state != self.start_state)\n",
    "                    and (state != self.terminal_state)\n",
    "                ):\n",
    "                    self._cliff[new_row, new_col] = True\n",
    "                    if not self.is_valid():\n",
    "                        self._cliff[new_row, new_col] = False\n",
    "                        continue\n",
    "                    self.cliff_positions.append(state)\n",
    "\n",
    "        # Calculate transition probabilities and rewards\n",
    "        self.P = {}\n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            self.P[s] = {a: [] for a in range(self.nA)}\n",
    "            self.P[s][UP] = self._calculate_transition_prob(position, [-1, 0])\n",
    "            self.P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1])\n",
    "            self.P[s][DOWN] = self._calculate_transition_prob(position, [1, 0])\n",
    "            self.P[s][LEFT] = self._calculate_transition_prob(position, [0, -1])\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta):\n",
    "        new_position = np.array(current) + np.array(delta)\n",
    "        new_position = self._limit_coordinates(new_position).astype(int)\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape)\n",
    "        if self._cliff[tuple(new_position)]:\n",
    "            return [(1.0, self.start_state_index, -100, False)]\n",
    "\n",
    "        terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "        is_terminated = tuple(new_position) == terminal_state\n",
    "        return [(1 / 3, new_state, -1, is_terminated)]\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(self):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((3, 0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r, c) in discovered:\n",
    "                discovered.add((r, c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= self.shape[0] or c_new < 0 or c_new >= self.shape[1]:\n",
    "                        continue\n",
    "                    if (r_new, c_new) == self.terminal_state:\n",
    "                        return True\n",
    "                    if not self._cliff[r_new][c_new]:\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in [0, 1, 2, 3]:\n",
    "            raise ValueError(f\"Invalid action {action}   must be in [0, 1, 2, 3]\")\n",
    "\n",
    "        if self.is_hardmode:\n",
    "            match action:\n",
    "                case 0:\n",
    "                    action = np.random.choice([0, 1, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 1:\n",
    "                    action = np.random.choice([0, 1, 2], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 2:\n",
    "                    action = np.random.choice([1, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 3:\n",
    "                    action = np.random.choice([0, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "\n",
    "        return super().step(action)\n",
    "\n",
    "    def _render_gui(self, mode):\n",
    "        try:\n",
    "            import pygame\n",
    "        except ImportError as e:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gymnasium[toy-text]`\"\n",
    "            ) from e\n",
    "        if self.window_surface is None:\n",
    "            pygame.init()\n",
    "\n",
    "            if mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                pygame.display.set_caption(\"CliffWalking - Edited by Audrina & Kian\")\n",
    "                self.window_surface = pygame.display.set_mode(self.window_size)\n",
    "            else:  # rgb_array\n",
    "                self.window_surface = pygame.Surface(self.window_size)\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "        if self.elf_images is None:\n",
    "            hikers = [\n",
    "                path.join(image_path, \"img/elf_up.png\"),\n",
    "                path.join(image_path, \"img/elf_right.png\"),\n",
    "                path.join(image_path, \"img/elf_down.png\"),\n",
    "                path.join(image_path, \"img/elf_left.png\"),\n",
    "            ]\n",
    "            self.elf_images = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in hikers\n",
    "            ]\n",
    "        if self.start_img is None:\n",
    "            file_name = path.join(image_path, \"img/stool.png\")\n",
    "            self.start_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.goal_img is None:\n",
    "            file_name = path.join(image_path, \"img/cookie.png\")\n",
    "            self.goal_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.mountain_bg_img is None:\n",
    "            bg_imgs = [\n",
    "                path.join(image_path, \"img/mountain_bg1.png\"),\n",
    "                path.join(image_path, \"img/mountain_bg2.png\"),\n",
    "            ]\n",
    "            self.mountain_bg_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in bg_imgs\n",
    "            ]\n",
    "        if self.near_cliff_img is None:\n",
    "            near_cliff_imgs = [\n",
    "                path.join(image_path, \"img/mountain_near-cliff1.png\"),\n",
    "                path.join(image_path, \"img/mountain_near-cliff2.png\"),\n",
    "            ]\n",
    "            self.near_cliff_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in near_cliff_imgs\n",
    "            ]\n",
    "        if self.cliff_img is None:\n",
    "            file_name = path.join(image_path, \"img/mountain_cliff.png\")\n",
    "            self.cliff_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            row, col = np.unravel_index(s, self.shape)\n",
    "            pos = (col * self.cell_size[0], row * self.cell_size[1])\n",
    "            check_board_mask = row % 2 ^ col % 2\n",
    "            self.window_surface.blit(self.mountain_bg_img[check_board_mask], pos)\n",
    "\n",
    "            if self._cliff[row, col]:\n",
    "                self.window_surface.blit(self.cliff_img, pos)\n",
    "            if s == self.start_state_index:\n",
    "                self.window_surface.blit(self.start_img, pos)\n",
    "            if s == self.nS - 1:\n",
    "                self.window_surface.blit(self.goal_img, pos)\n",
    "            if s == self.s:\n",
    "                elf_pos = (pos[0], pos[1] - 0.1 * self.cell_size[1])\n",
    "                last_action = self.lastaction if self.lastaction is not None else 2\n",
    "                self.window_surface.blit(self.elf_images[last_action], elf_pos)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.window_surface)), axes=(1, 0, 2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3bfe55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T07:06:03.777861500Z",
     "start_time": "2023-12-06T07:06:03.167643200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {0: [(0.3333333333333333, 0, -1, False)],\n  1: [(0.3333333333333333, 1, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 0, -1, False)]},\n 1: {0: [(0.3333333333333333, 1, -1, False)],\n  1: [(0.3333333333333333, 2, -1, False)],\n  2: [(0.3333333333333333, 13, -1, False)],\n  3: [(0.3333333333333333, 0, -1, False)]},\n 2: {0: [(0.3333333333333333, 2, -1, False)],\n  1: [(0.3333333333333333, 3, -1, False)],\n  2: [(0.3333333333333333, 14, -1, False)],\n  3: [(0.3333333333333333, 1, -1, False)]},\n 3: {0: [(0.3333333333333333, 3, -1, False)],\n  1: [(0.3333333333333333, 4, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 2, -1, False)]},\n 4: {0: [(0.3333333333333333, 4, -1, False)],\n  1: [(0.3333333333333333, 5, -1, False)],\n  2: [(0.3333333333333333, 16, -1, False)],\n  3: [(0.3333333333333333, 3, -1, False)]},\n 5: {0: [(0.3333333333333333, 5, -1, False)],\n  1: [(0.3333333333333333, 6, -1, False)],\n  2: [(0.3333333333333333, 17, -1, False)],\n  3: [(0.3333333333333333, 4, -1, False)]},\n 6: {0: [(0.3333333333333333, 6, -1, False)],\n  1: [(0.3333333333333333, 7, -1, False)],\n  2: [(0.3333333333333333, 18, -1, False)],\n  3: [(0.3333333333333333, 5, -1, False)]},\n 7: {0: [(0.3333333333333333, 7, -1, False)],\n  1: [(0.3333333333333333, 8, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 6, -1, False)]},\n 8: {0: [(0.3333333333333333, 8, -1, False)],\n  1: [(0.3333333333333333, 9, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 7, -1, False)]},\n 9: {0: [(0.3333333333333333, 9, -1, False)],\n  1: [(0.3333333333333333, 10, -1, False)],\n  2: [(0.3333333333333333, 21, -1, False)],\n  3: [(0.3333333333333333, 8, -1, False)]},\n 10: {0: [(0.3333333333333333, 10, -1, False)],\n  1: [(0.3333333333333333, 11, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 9, -1, False)]},\n 11: {0: [(0.3333333333333333, 11, -1, False)],\n  1: [(0.3333333333333333, 11, -1, False)],\n  2: [(0.3333333333333333, 23, -1, False)],\n  3: [(0.3333333333333333, 10, -1, False)]},\n 12: {0: [(0.3333333333333333, 0, -1, False)],\n  1: [(0.3333333333333333, 13, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(1.0, 36, -100, False)]},\n 13: {0: [(0.3333333333333333, 1, -1, False)],\n  1: [(0.3333333333333333, 14, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(1.0, 36, -100, False)]},\n 14: {0: [(0.3333333333333333, 2, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 13, -1, False)]},\n 15: {0: [(0.3333333333333333, 3, -1, False)],\n  1: [(0.3333333333333333, 16, -1, False)],\n  2: [(0.3333333333333333, 27, -1, False)],\n  3: [(0.3333333333333333, 14, -1, False)]},\n 16: {0: [(0.3333333333333333, 4, -1, False)],\n  1: [(0.3333333333333333, 17, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(1.0, 36, -100, False)]},\n 17: {0: [(0.3333333333333333, 5, -1, False)],\n  1: [(0.3333333333333333, 18, -1, False)],\n  2: [(0.3333333333333333, 29, -1, False)],\n  3: [(0.3333333333333333, 16, -1, False)]},\n 18: {0: [(0.3333333333333333, 6, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 30, -1, False)],\n  3: [(0.3333333333333333, 17, -1, False)]},\n 19: {0: [(0.3333333333333333, 7, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 31, -1, False)],\n  3: [(0.3333333333333333, 18, -1, False)]},\n 20: {0: [(0.3333333333333333, 8, -1, False)],\n  1: [(0.3333333333333333, 21, -1, False)],\n  2: [(0.3333333333333333, 32, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 21: {0: [(0.3333333333333333, 9, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 33, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 22: {0: [(0.3333333333333333, 10, -1, False)],\n  1: [(0.3333333333333333, 23, -1, False)],\n  2: [(0.3333333333333333, 34, -1, False)],\n  3: [(0.3333333333333333, 21, -1, False)]},\n 23: {0: [(0.3333333333333333, 11, -1, False)],\n  1: [(0.3333333333333333, 23, -1, False)],\n  2: [(0.3333333333333333, 35, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 24: {0: [(1.0, 36, -100, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 36, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 25: {0: [(0.3333333333333333, 13, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 37, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 26: {0: [(0.3333333333333333, 14, -1, False)],\n  1: [(0.3333333333333333, 27, -1, False)],\n  2: [(0.3333333333333333, 38, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 27: {0: [(1.0, 36, -100, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 39, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 28: {0: [(0.3333333333333333, 16, -1, False)],\n  1: [(0.3333333333333333, 29, -1, False)],\n  2: [(0.3333333333333333, 40, -1, False)],\n  3: [(0.3333333333333333, 27, -1, False)]},\n 29: {0: [(0.3333333333333333, 17, -1, False)],\n  1: [(0.3333333333333333, 30, -1, False)],\n  2: [(0.3333333333333333, 41, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 30: {0: [(0.3333333333333333, 18, -1, False)],\n  1: [(0.3333333333333333, 31, -1, False)],\n  2: [(0.3333333333333333, 42, -1, False)],\n  3: [(0.3333333333333333, 29, -1, False)]},\n 31: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 32, -1, False)],\n  2: [(0.3333333333333333, 43, -1, False)],\n  3: [(0.3333333333333333, 30, -1, False)]},\n 32: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 33, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 31, -1, False)]},\n 33: {0: [(0.3333333333333333, 21, -1, False)],\n  1: [(0.3333333333333333, 34, -1, False)],\n  2: [(0.3333333333333333, 45, -1, False)],\n  3: [(0.3333333333333333, 32, -1, False)]},\n 34: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 35, -1, False)],\n  2: [(0.3333333333333333, 46, -1, False)],\n  3: [(0.3333333333333333, 33, -1, False)]},\n 35: {0: [(0.3333333333333333, 23, -1, False)],\n  1: [(0.3333333333333333, 35, -1, False)],\n  2: [(0.3333333333333333, 47, -1, True)],\n  3: [(0.3333333333333333, 34, -1, False)]},\n 36: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 37, -1, False)],\n  2: [(0.3333333333333333, 36, -1, False)],\n  3: [(0.3333333333333333, 36, -1, False)]},\n 37: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 38, -1, False)],\n  2: [(0.3333333333333333, 37, -1, False)],\n  3: [(0.3333333333333333, 36, -1, False)]},\n 38: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 39, -1, False)],\n  2: [(0.3333333333333333, 38, -1, False)],\n  3: [(0.3333333333333333, 37, -1, False)]},\n 39: {0: [(0.3333333333333333, 27, -1, False)],\n  1: [(0.3333333333333333, 40, -1, False)],\n  2: [(0.3333333333333333, 39, -1, False)],\n  3: [(0.3333333333333333, 38, -1, False)]},\n 40: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 41, -1, False)],\n  2: [(0.3333333333333333, 40, -1, False)],\n  3: [(0.3333333333333333, 39, -1, False)]},\n 41: {0: [(0.3333333333333333, 29, -1, False)],\n  1: [(0.3333333333333333, 42, -1, False)],\n  2: [(0.3333333333333333, 41, -1, False)],\n  3: [(0.3333333333333333, 40, -1, False)]},\n 42: {0: [(0.3333333333333333, 30, -1, False)],\n  1: [(0.3333333333333333, 43, -1, False)],\n  2: [(0.3333333333333333, 42, -1, False)],\n  3: [(0.3333333333333333, 41, -1, False)]},\n 43: {0: [(0.3333333333333333, 31, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 43, -1, False)],\n  3: [(0.3333333333333333, 42, -1, False)]},\n 44: {0: [(0.3333333333333333, 32, -1, False)],\n  1: [(0.3333333333333333, 45, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 43, -1, False)]},\n 45: {0: [(0.3333333333333333, 33, -1, False)],\n  1: [(0.3333333333333333, 46, -1, False)],\n  2: [(0.3333333333333333, 45, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 46: {0: [(0.3333333333333333, 34, -1, False)],\n  1: [(0.3333333333333333, 47, -1, True)],\n  2: [(0.3333333333333333, 46, -1, False)],\n  3: [(0.3333333333333333, 45, -1, False)]},\n 47: {0: [(0.3333333333333333, 35, -1, False)],\n  1: [(0.3333333333333333, 47, -1, True)],\n  2: [(0.3333333333333333, 47, -1, True)],\n  3: [(0.3333333333333333, 46, -1, False)]}}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an environment\n",
    "env = CliffWalking(render_mode=\"human\")\n",
    "observation, info = env.reset(seed=30)\n",
    "env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "inf = env.P.keys()\n",
    "print(list(range(4)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T14:51:42.767077500Z",
     "start_time": "2023-12-06T14:51:42.747143400Z"
    }
   },
   "id": "caa2ba4a830e3203"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def policy_iteration(states, actions, P, gamma, theta=0.0001):\n",
    "    # Initialize random policy\n",
    "    policy = {state: random.choice(actions) for state in states}\n",
    "    while True:\n",
    "        # Policy evaluation\n",
    "        V = {state: 0 for state in states}\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for state in states:\n",
    "                v = V[state]\n",
    "                action = policy[state]\n",
    "                value = 0\n",
    "                for next_state in states:\n",
    "                    info = P[state][action][0]\n",
    "                    if info[1] == next_state:\n",
    "                        value += info[0] * (info[2] + gamma * V[next_state])\n",
    "                V[state] = value                \n",
    "                delta = max(delta, abs(v - V[state]))\n",
    "            if delta < theta:\n",
    "                break\n",
    "\n",
    "        # Policy improvement\n",
    "        policy_stable = True\n",
    "        for state in states:\n",
    "            old_action = policy[state]\n",
    "            max_value = float('-inf')\n",
    "            best_action = None\n",
    "            for action in actions:\n",
    "                action_value = 0\n",
    "                for next_state in states:\n",
    "                    info = P[state][action][0]\n",
    "                    if info[1] == next_state:\n",
    "                        action_value += info[0] * (info[2] + gamma * V[next_state])\n",
    "                if action_value > max_value:\n",
    "                    max_value = action_value\n",
    "                    best_action = action\n",
    "            policy[state] = best_action\n",
    "            if old_action != best_action:\n",
    "                policy_stable = False\n",
    "\n",
    "        if policy_stable:\n",
    "            break\n",
    "\n",
    "    return V, policy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9e7a97fda7c5b6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0bed6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T06:57:08.771909Z",
     "start_time": "2023-12-06T06:57:08.723036900Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CliffWalking' object has no attribute 'states'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m max_iter_number \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m __ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_iter_number):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# TODO: Implement the agent policy here\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# Note: .sample() is used to sample random action from the environment's action space\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m     pi \u001B[38;5;241m=\u001B[39m {s: random\u001B[38;5;241m.\u001B[39mchoice(env\u001B[38;5;241m.\u001B[39mactions(s)) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m env\u001B[38;5;241m.\u001B[39mstates}\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Choose an action (Replace this random action with your agent's policy)\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     action \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39msample()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CliffWalking' object has no attribute 'states'"
     ]
    }
   ],
   "source": [
    "# Define the maximum number of iterations\n",
    "max_iter_number = 1000\n",
    "\n",
    "for __ in range(max_iter_number):\n",
    "    # TODO: Implement the agent policy here\n",
    "    # Note: .sample() is used to sample random action from the environment's action space\n",
    "    states = env.P.keys()\n",
    "    actions = list(range(4))\n",
    "    V, policy = policy_iteration(states, actions, env.P, 0.9) \n",
    "    \n",
    "    # Choose an action (Replace this random action with your agent's policy)\n",
    "    #action = env.action_space.sample()\n",
    "\n",
    "    # Perform the action and receive feedback from the environment\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    if done or truncated:\n",
    "        observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f712696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T17:41:35.621076Z",
     "start_time": "2023-12-04T17:41:35.621076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "47b877d909c27f8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
