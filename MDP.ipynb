{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43732b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:11:00.754850Z",
     "start_time": "2023-12-06T18:11:00.752753800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import nessary libraries\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.cliffwalking import CliffWalkingEnv\n",
    "from gymnasium.error import DependencyNotInstalled\n",
    "from os import path\n",
    "from numpy import argmax\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a570958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:11:00.791384300Z",
     "start_time": "2023-12-06T18:11:00.773073600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do not change this class\n",
    "UP = 0\n",
    "RIGHT = 1\n",
    "DOWN = 2\n",
    "LEFT = 3\n",
    "image_path = path.join(path.dirname(gym.__file__), \"envs\", \"toy_text\")\n",
    "\n",
    "class CliffWalking(CliffWalkingEnv):\n",
    "    def __init__(self, is_hardmode=True, num_cliffs=10, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.is_hardmode = is_hardmode\n",
    "\n",
    "        # Generate random cliff positions\n",
    "        if self.is_hardmode:\n",
    "            self.num_cliffs = num_cliffs\n",
    "            self._cliff = np.zeros(self.shape, dtype=bool)\n",
    "            self.start_state = (3, 0)\n",
    "            self.terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "            self.cliff_positions = []\n",
    "            while len(self.cliff_positions) < self.num_cliffs:\n",
    "                new_row = np.random.randint(0, 4)\n",
    "                new_col = np.random.randint(0, 11)\n",
    "                state = (new_row, new_col)\n",
    "                if (\n",
    "                    (state not in self.cliff_positions)\n",
    "                    and (state != self.start_state)\n",
    "                    and (state != self.terminal_state)\n",
    "                ):\n",
    "                    self._cliff[new_row, new_col] = True\n",
    "                    if not self.is_valid():\n",
    "                        self._cliff[new_row, new_col] = False\n",
    "                        continue\n",
    "                    self.cliff_positions.append(state)\n",
    "\n",
    "        # Calculate transition probabilities and rewards\n",
    "        self.P = {}\n",
    "        for s in range(self.nS):\n",
    "            position = np.unravel_index(s, self.shape)\n",
    "            self.P[s] = {a: [] for a in range(self.nA)}\n",
    "            self.P[s][UP] = self._calculate_transition_prob(position, [-1, 0])\n",
    "            self.P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1])\n",
    "            self.P[s][DOWN] = self._calculate_transition_prob(position, [1, 0])\n",
    "            self.P[s][LEFT] = self._calculate_transition_prob(position, [0, -1])\n",
    "\n",
    "    def _calculate_transition_prob(self, current, delta):\n",
    "        new_position = np.array(current) + np.array(delta)\n",
    "        new_position = self._limit_coordinates(new_position).astype(int)\n",
    "        new_state = np.ravel_multi_index(tuple(new_position), self.shape)\n",
    "        if self._cliff[tuple(new_position)]:\n",
    "            return [(1.0, self.start_state_index, -100, False)]\n",
    "\n",
    "        terminal_state = (self.shape[0] - 1, self.shape[1] - 1)\n",
    "        is_terminated = tuple(new_position) == terminal_state\n",
    "        return [(1 / 3, new_state, -1, is_terminated)]\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(self):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((3, 0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r, c) in discovered:\n",
    "                discovered.add((r, c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= self.shape[0] or c_new < 0 or c_new >= self.shape[1]:\n",
    "                        continue\n",
    "                    if (r_new, c_new) == self.terminal_state:\n",
    "                        return True\n",
    "                    if not self._cliff[r_new][c_new]:\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in [0, 1, 2, 3]:\n",
    "            raise ValueError(f\"Invalid action {action}   must be in [0, 1, 2, 3]\")\n",
    "\n",
    "        if self.is_hardmode:\n",
    "            match action:\n",
    "                case 0:\n",
    "                    action = np.random.choice([0, 1, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 1:\n",
    "                    action = np.random.choice([0, 1, 2], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 2:\n",
    "                    action = np.random.choice([1, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "                case 3:\n",
    "                    action = np.random.choice([0, 2, 3], p=[1 / 3, 1 / 3, 1 / 3])\n",
    "\n",
    "        return super().step(action)\n",
    "\n",
    "    def _render_gui(self, mode):\n",
    "        try:\n",
    "            import pygame\n",
    "        except ImportError as e:\n",
    "            raise DependencyNotInstalled(\n",
    "                \"pygame is not installed, run `pip install gymnasium[toy-text]`\"\n",
    "            ) from e\n",
    "        if self.window_surface is None:\n",
    "            pygame.init()\n",
    "\n",
    "            if mode == \"human\":\n",
    "                pygame.display.init()\n",
    "                pygame.display.set_caption(\"CliffWalking - Edited by Audrina & Kian\")\n",
    "                self.window_surface = pygame.display.set_mode(self.window_size)\n",
    "            else:  # rgb_array\n",
    "                self.window_surface = pygame.Surface(self.window_size)\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "        if self.elf_images is None:\n",
    "            hikers = [\n",
    "                path.join(image_path, \"img/elf_up.png\"),\n",
    "                path.join(image_path, \"img/elf_right.png\"),\n",
    "                path.join(image_path, \"img/elf_down.png\"),\n",
    "                path.join(image_path, \"img/elf_left.png\"),\n",
    "            ]\n",
    "            self.elf_images = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in hikers\n",
    "            ]\n",
    "        if self.start_img is None:\n",
    "            file_name = path.join(image_path, \"img/stool.png\")\n",
    "            self.start_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.goal_img is None:\n",
    "            file_name = path.join(image_path, \"img/cookie.png\")\n",
    "            self.goal_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "        if self.mountain_bg_img is None:\n",
    "            bg_imgs = [\n",
    "                path.join(image_path, \"img/mountain_bg1.png\"),\n",
    "                path.join(image_path, \"img/mountain_bg2.png\"),\n",
    "            ]\n",
    "            self.mountain_bg_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in bg_imgs\n",
    "            ]\n",
    "        if self.near_cliff_img is None:\n",
    "            near_cliff_imgs = [\n",
    "                path.join(image_path, \"img/mountain_near-cliff1.png\"),\n",
    "                path.join(image_path, \"img/mountain_near-cliff2.png\"),\n",
    "            ]\n",
    "            self.near_cliff_img = [\n",
    "                pygame.transform.scale(pygame.image.load(f_name), self.cell_size)\n",
    "                for f_name in near_cliff_imgs\n",
    "            ]\n",
    "        if self.cliff_img is None:\n",
    "            file_name = path.join(image_path, \"img/mountain_cliff.png\")\n",
    "            self.cliff_img = pygame.transform.scale(\n",
    "                pygame.image.load(file_name), self.cell_size\n",
    "            )\n",
    "\n",
    "        for s in range(self.nS):\n",
    "            row, col = np.unravel_index(s, self.shape)\n",
    "            pos = (col * self.cell_size[0], row * self.cell_size[1])\n",
    "            check_board_mask = row % 2 ^ col % 2\n",
    "            self.window_surface.blit(self.mountain_bg_img[check_board_mask], pos)\n",
    "\n",
    "            if self._cliff[row, col]:\n",
    "                self.window_surface.blit(self.cliff_img, pos)\n",
    "            if s == self.start_state_index:\n",
    "                self.window_surface.blit(self.start_img, pos)\n",
    "            if s == self.nS - 1:\n",
    "                self.window_surface.blit(self.goal_img, pos)\n",
    "            if s == self.s:\n",
    "                elf_pos = (pos[0], pos[1] - 0.1 * self.cell_size[1])\n",
    "                last_action = self.lastaction if self.lastaction is not None else 2\n",
    "                self.window_surface.blit(self.elf_images[last_action], elf_pos)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.window_surface)), axes=(1, 0, 2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e3bfe55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:11:43.650367200Z",
     "start_time": "2023-12-06T18:11:43.371217600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: {0: [(0.3333333333333333, 0, -1, False)],\n  1: [(0.3333333333333333, 1, -1, False)],\n  2: [(0.3333333333333333, 12, -1, False)],\n  3: [(0.3333333333333333, 0, -1, False)]},\n 1: {0: [(0.3333333333333333, 1, -1, False)],\n  1: [(0.3333333333333333, 2, -1, False)],\n  2: [(0.3333333333333333, 13, -1, False)],\n  3: [(0.3333333333333333, 0, -1, False)]},\n 2: {0: [(0.3333333333333333, 2, -1, False)],\n  1: [(0.3333333333333333, 3, -1, False)],\n  2: [(0.3333333333333333, 14, -1, False)],\n  3: [(0.3333333333333333, 1, -1, False)]},\n 3: {0: [(0.3333333333333333, 3, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 2, -1, False)]},\n 4: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 5, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 3, -1, False)]},\n 5: {0: [(0.3333333333333333, 5, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 17, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 6: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 7, -1, False)],\n  2: [(0.3333333333333333, 18, -1, False)],\n  3: [(0.3333333333333333, 5, -1, False)]},\n 7: {0: [(0.3333333333333333, 7, -1, False)],\n  1: [(0.3333333333333333, 8, -1, False)],\n  2: [(0.3333333333333333, 19, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 8: {0: [(0.3333333333333333, 8, -1, False)],\n  1: [(0.3333333333333333, 9, -1, False)],\n  2: [(0.3333333333333333, 20, -1, False)],\n  3: [(0.3333333333333333, 7, -1, False)]},\n 9: {0: [(0.3333333333333333, 9, -1, False)],\n  1: [(0.3333333333333333, 10, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 8, -1, False)]},\n 10: {0: [(0.3333333333333333, 10, -1, False)],\n  1: [(0.3333333333333333, 11, -1, False)],\n  2: [(0.3333333333333333, 22, -1, False)],\n  3: [(0.3333333333333333, 9, -1, False)]},\n 11: {0: [(0.3333333333333333, 11, -1, False)],\n  1: [(0.3333333333333333, 11, -1, False)],\n  2: [(0.3333333333333333, 23, -1, False)],\n  3: [(0.3333333333333333, 10, -1, False)]},\n 12: {0: [(0.3333333333333333, 0, -1, False)],\n  1: [(0.3333333333333333, 13, -1, False)],\n  2: [(0.3333333333333333, 24, -1, False)],\n  3: [(0.3333333333333333, 12, -1, False)]},\n 13: {0: [(0.3333333333333333, 1, -1, False)],\n  1: [(0.3333333333333333, 14, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 12, -1, False)]},\n 14: {0: [(0.3333333333333333, 2, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 26, -1, False)],\n  3: [(0.3333333333333333, 13, -1, False)]},\n 15: {0: [(0.3333333333333333, 3, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 14, -1, False)]},\n 16: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 17, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(1.0, 36, -100, False)]},\n 17: {0: [(0.3333333333333333, 5, -1, False)],\n  1: [(0.3333333333333333, 18, -1, False)],\n  2: [(0.3333333333333333, 29, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 18: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 19, -1, False)],\n  2: [(0.3333333333333333, 30, -1, False)],\n  3: [(0.3333333333333333, 17, -1, False)]},\n 19: {0: [(0.3333333333333333, 7, -1, False)],\n  1: [(0.3333333333333333, 20, -1, False)],\n  2: [(0.3333333333333333, 31, -1, False)],\n  3: [(0.3333333333333333, 18, -1, False)]},\n 20: {0: [(0.3333333333333333, 8, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 32, -1, False)],\n  3: [(0.3333333333333333, 19, -1, False)]},\n 21: {0: [(0.3333333333333333, 9, -1, False)],\n  1: [(0.3333333333333333, 22, -1, False)],\n  2: [(0.3333333333333333, 33, -1, False)],\n  3: [(0.3333333333333333, 20, -1, False)]},\n 22: {0: [(0.3333333333333333, 10, -1, False)],\n  1: [(0.3333333333333333, 23, -1, False)],\n  2: [(0.3333333333333333, 34, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 23: {0: [(0.3333333333333333, 11, -1, False)],\n  1: [(0.3333333333333333, 23, -1, False)],\n  2: [(0.3333333333333333, 35, -1, False)],\n  3: [(0.3333333333333333, 22, -1, False)]},\n 24: {0: [(0.3333333333333333, 12, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 36, -1, False)],\n  3: [(0.3333333333333333, 24, -1, False)]},\n 25: {0: [(0.3333333333333333, 13, -1, False)],\n  1: [(0.3333333333333333, 26, -1, False)],\n  2: [(0.3333333333333333, 37, -1, False)],\n  3: [(0.3333333333333333, 24, -1, False)]},\n 26: {0: [(0.3333333333333333, 14, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 38, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 27: {0: [(1.0, 36, -100, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 39, -1, False)],\n  3: [(0.3333333333333333, 26, -1, False)]},\n 28: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 29, -1, False)],\n  2: [(0.3333333333333333, 40, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 29: {0: [(0.3333333333333333, 17, -1, False)],\n  1: [(0.3333333333333333, 30, -1, False)],\n  2: [(0.3333333333333333, 41, -1, False)],\n  3: [(1.0, 36, -100, False)]},\n 30: {0: [(0.3333333333333333, 18, -1, False)],\n  1: [(0.3333333333333333, 31, -1, False)],\n  2: [(0.3333333333333333, 42, -1, False)],\n  3: [(0.3333333333333333, 29, -1, False)]},\n 31: {0: [(0.3333333333333333, 19, -1, False)],\n  1: [(0.3333333333333333, 32, -1, False)],\n  2: [(0.3333333333333333, 43, -1, False)],\n  3: [(0.3333333333333333, 30, -1, False)]},\n 32: {0: [(0.3333333333333333, 20, -1, False)],\n  1: [(0.3333333333333333, 33, -1, False)],\n  2: [(0.3333333333333333, 44, -1, False)],\n  3: [(0.3333333333333333, 31, -1, False)]},\n 33: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 34, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 32, -1, False)]},\n 34: {0: [(0.3333333333333333, 22, -1, False)],\n  1: [(0.3333333333333333, 35, -1, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 33, -1, False)]},\n 35: {0: [(0.3333333333333333, 23, -1, False)],\n  1: [(0.3333333333333333, 35, -1, False)],\n  2: [(0.3333333333333333, 47, -1, True)],\n  3: [(0.3333333333333333, 34, -1, False)]},\n 36: {0: [(0.3333333333333333, 24, -1, False)],\n  1: [(0.3333333333333333, 37, -1, False)],\n  2: [(0.3333333333333333, 36, -1, False)],\n  3: [(0.3333333333333333, 36, -1, False)]},\n 37: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 38, -1, False)],\n  2: [(0.3333333333333333, 37, -1, False)],\n  3: [(0.3333333333333333, 36, -1, False)]},\n 38: {0: [(0.3333333333333333, 26, -1, False)],\n  1: [(0.3333333333333333, 39, -1, False)],\n  2: [(0.3333333333333333, 38, -1, False)],\n  3: [(0.3333333333333333, 37, -1, False)]},\n 39: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 40, -1, False)],\n  2: [(0.3333333333333333, 39, -1, False)],\n  3: [(0.3333333333333333, 38, -1, False)]},\n 40: {0: [(1.0, 36, -100, False)],\n  1: [(0.3333333333333333, 41, -1, False)],\n  2: [(0.3333333333333333, 40, -1, False)],\n  3: [(0.3333333333333333, 39, -1, False)]},\n 41: {0: [(0.3333333333333333, 29, -1, False)],\n  1: [(0.3333333333333333, 42, -1, False)],\n  2: [(0.3333333333333333, 41, -1, False)],\n  3: [(0.3333333333333333, 40, -1, False)]},\n 42: {0: [(0.3333333333333333, 30, -1, False)],\n  1: [(0.3333333333333333, 43, -1, False)],\n  2: [(0.3333333333333333, 42, -1, False)],\n  3: [(0.3333333333333333, 41, -1, False)]},\n 43: {0: [(0.3333333333333333, 31, -1, False)],\n  1: [(0.3333333333333333, 44, -1, False)],\n  2: [(0.3333333333333333, 43, -1, False)],\n  3: [(0.3333333333333333, 42, -1, False)]},\n 44: {0: [(0.3333333333333333, 32, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(0.3333333333333333, 44, -1, False)],\n  3: [(0.3333333333333333, 43, -1, False)]},\n 45: {0: [(0.3333333333333333, 33, -1, False)],\n  1: [(1.0, 36, -100, False)],\n  2: [(1.0, 36, -100, False)],\n  3: [(0.3333333333333333, 44, -1, False)]},\n 46: {0: [(0.3333333333333333, 34, -1, False)],\n  1: [(0.3333333333333333, 47, -1, True)],\n  2: [(1.0, 36, -100, False)],\n  3: [(1.0, 36, -100, False)]},\n 47: {0: [(0.3333333333333333, 35, -1, False)],\n  1: [(0.3333333333333333, 47, -1, True)],\n  2: [(0.3333333333333333, 47, -1, True)],\n  3: [(1.0, 36, -100, False)]}}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an environment\n",
    "env = CliffWalking(render_mode=\"human\")\n",
    "observation, info = env.reset(seed=30)\n",
    "env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def policy_iteration(states, actions, P, gamma, theta=0.001):\n",
    "    # Initialize random policy\n",
    "    policy = {state: random.choice(actions) for state in states}\n",
    "    while True:\n",
    "        # Policy evaluation\n",
    "        V = {state: 0 for state in states}\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for state in states:\n",
    "                v = V[state]\n",
    "                action = policy[state]\n",
    "                value = 0\n",
    "                for next_state in states:\n",
    "                    info = P[state][action][0]\n",
    "                    if info[1] == next_state:\n",
    "                        if info[3] is True:\n",
    "                            value += info[0] * (100 + gamma * V[next_state])\n",
    "                        else:\n",
    "                            value += info[0] * (info[2] + gamma * V[next_state])\n",
    "                V[state] = value                \n",
    "                delta = max(delta, abs(v - V[state]))\n",
    "            if delta < theta:\n",
    "                break\n",
    "\n",
    "        # Policy improvement\n",
    "        policy_stable = True\n",
    "        for state in states:\n",
    "            old_action = policy[state]\n",
    "            max_value = float('-inf')\n",
    "            best_action = None\n",
    "            for action in actions:\n",
    "                action_value = 0\n",
    "                for next_state in states:\n",
    "                    info = P[state][action][0]\n",
    "                    if info[1] == next_state:\n",
    "                        if info[3] is True:\n",
    "                            action_value += info[0] * (100 + gamma * V[next_state])\n",
    "                        else:\n",
    "                            action_value += info[0] * (info[2] + gamma * V[next_state])\n",
    "                if action_value > max_value:\n",
    "                    max_value = action_value\n",
    "                    best_action = action\n",
    "            # policy[state] = best_action\n",
    "            if old_action != best_action:\n",
    "                policy[state] = best_action\n",
    "                policy_stable = False\n",
    "        if policy_stable:\n",
    "            break\n",
    "\n",
    "    return V, policy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T18:11:59.103596900Z",
     "start_time": "2023-12-06T18:11:59.100599600Z"
    }
   },
   "id": "eb9e7a97fda7c5b6"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e0bed6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:12:08.640038200Z",
     "start_time": "2023-12-06T18:12:08.324718400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 3, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 3, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 3, 3: 3, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 3, 25: 3, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 0, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 3, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 3, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 2, 12: 0, 13: 0, 14: 0, 15: 0, 16: 1, 17: 1, 18: 1, 19: 1, 20: 2, 21: 1, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 2, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 0, 45: 0, 46: 1, 47: 1}\n"
     ]
    }
   ],
   "source": [
    "# Define the maximum number of iterations\n",
    "max_iter_number = 10\n",
    "\n",
    "for __ in range(max_iter_number):\n",
    "    # TODO: Implement the agent policy here\n",
    "    # Note: .sample() is used to sample random action from the environment's action space\n",
    "    states = env.P.keys()\n",
    "    actions = list(range(4))\n",
    "    V, policy = policy_iteration(states, actions, env.P, 0.9) \n",
    "    # print(policy)\n",
    "    \n",
    "    # Choose an action (Replace this random action with your agent's policy)\n",
    "    # action = policy\n",
    "    \n",
    "    # Perform the action and receive feedback from the environment\n",
    "    # next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    # if done or truncated:\n",
    "    #     observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f712696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:11:01.354339200Z",
     "start_time": "2023-12-06T18:11:01.347050800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T18:11:01.354339200Z",
     "start_time": "2023-12-06T18:11:01.350829400Z"
    }
   },
   "id": "47b877d909c27f8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
